{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import firecloud.api as fapi\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "\n",
    "bucket = \"fc-secure-d99fbd65-eb27-4989-95b4-4cf559aa7d36\"\n",
    "\n",
    "namespace = \"testmybroad\"\n",
    "workspace = \"Macosko-Pipelines\"\n",
    "cnamespace = \"macosko-pipelines\"\n",
    "\n",
    "special = {\"ref\", \"puck\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_run_data(run_data):\n",
    "    assert type(run_data) == dict\n",
    "    for workflow in run_data:\n",
    "        assert workflow in [\"cellranger-count\", \"spatial-count\", \"positioning\", \"reconstruction\"]\n",
    "        assert type(run_data[workflow]) == list\n",
    "        assert len(run_data[workflow]) > 0\n",
    "        print(f\"{workflow} samples: \")\n",
    "        for sample in run_data[workflow]:\n",
    "            print(f\"\\t{sample}\")\n",
    "            assert type(sample) == dict\n",
    "            assert len(sample) > 0\n",
    "            if workflow == \"cellranger-count\": # one is ref, other is an index\n",
    "                assert len(sample) == 2\n",
    "                assert \"ref\" in sample and type(sample[\"ref\"]) == str\n",
    "                assert len(set(sample.keys()).intersection(special)) == 1\n",
    "            if workflow == \"spatial-count\": # one puck, rest are index\n",
    "                assert len(sample) >= 2\n",
    "                assert \"puck\" in sample and type(sample[\"puck\"]) == list and all(type(puck) == str for puck in sample[\"puck\"])\n",
    "                assert len(set(sample.keys()).intersection(special)) == 1\n",
    "            [validate_lanes(sample[index]) for index in sample if index not in special]    \n",
    "\n",
    "def validate_lanes(lanes):\n",
    "    assert type(lanes) == list\n",
    "    assert all(isinstance(L, int) and 1 <= L <= 8 for L in lanes)\n",
    "\n",
    "def get_fastqs_and_size_and_id(bcl, sample):\n",
    "    # Get the sizes of all fastqs in the bucket\n",
    "    sizes = !gsutil du gs://{bucket}/fastqs/{bcl}\n",
    "    sizes = [size.split() for size in sizes]\n",
    "    sizes = [(size[0], size[1]) for size in sizes if size[1][-9:] == \".fastq.gz\"]\n",
    "    sizes = [size for size in sizes if \"_I1_\" not in size[1] and \"_I2_\" not in size[1]]\n",
    "    \n",
    "    # Delete non-index keys\n",
    "    sample = {k: v for k, v in sample.items() if k not in special}\n",
    "    \n",
    "    # Filter down to the fastqs in our sample\n",
    "    fastqs = [] ; total_size = 0\n",
    "    for index in sample:\n",
    "        index_sizes = [size for size in sizes if f\"{index}_S\" in size[1]]\n",
    "        if len(sample[index]) > 0:\n",
    "            lanes = [f\"_L00{L}_\" for L in sample[index]]\n",
    "            index_sizes = [size for size in index_sizes if any(lane in size[1] for lane in lanes)]\n",
    "            assert len(index_sizes) == len(lanes)*2\n",
    "        \n",
    "        assert len(index_sizes) % 2 == 0\n",
    "        assert len(set([re.sub(r'_L00[1-8]_', '__', size[1]) for size in index_sizes])) == 2\n",
    "        \n",
    "        fastqs += [size[1] for size in index_sizes]\n",
    "        total_size += sum([int(size[0]) for size in index_sizes])\n",
    "    \n",
    "    total_size_GiB = math.ceil(total_size/1024/1024/1024)\n",
    "    print(f\"{len(fastqs)} fastqs found\")\n",
    "    print(f\"total size: {total_size_GiB} GiB\")\n",
    "    \n",
    "    # Create a unique id\n",
    "    ids = [index if len(sample[index]) == 0 else index+'-'+''.join(map(str, sample[index])) for index in sample]\n",
    "    id = bcl+\"/\"+'_'.join(ids)\n",
    "    print(f\"id: {id}\")\n",
    "    \n",
    "    # Return\n",
    "    return fastqs, total_size_GiB, id\n",
    "\n",
    "def submit(method, user_comment=\"\"):\n",
    "    # Validate the configuration\n",
    "    res = fapi.validate_config(namespace, workspace, cnamespace, method).json()\n",
    "    assert res[\"extraInputs\"] == [], f\"ERROR: extra input: \\n{res['extraInputs']}\"\n",
    "    assert res[\"invalidInputs\"] == {}, f\"ERROR: invalid input: \\n{res['invalidInputs']}\"\n",
    "    assert res[\"invalidOutputs\"] == {}, f\"ERROR: invalid output: \\n{res['invalidOutputs']}\"\n",
    "    assert res[\"missingInputs\"] == [], f\"ERROR: missing input: \\n{res['missingInputs']}\"\n",
    "    \n",
    "    # Submit the job\n",
    "    fapi.create_submission(namespace, workspace, cnamespace, method, user_comment=user_comment).json()\n",
    "    print(f\"Submitted {method} {user_comment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cellranger_count(bcl, sample, technique=\"cellranger\", params=\"\", mm=5):\n",
    "    # Get the paths and sizes of the fastqs\n",
    "    fastqs, total_size_GiB, id = get_fastqs_and_size_and_id(bcl, sample)\n",
    "    mem_GiB = 64\n",
    "    disk_GiB = max(math.ceil(total_size_GiB * mm + 20), 128)\n",
    "    assert disk_GiB <= 6000, \"Increase disk cap\"\n",
    "    \n",
    "    # Assert the output doesn't exist already\n",
    "    files = !gsutil ls gs://{bucket}/cellranger-count/{id} ; assert len(files) == 1\n",
    "\n",
    "    # Get the reference\n",
    "    reference = f\"gs://{bucket}/references/{sample['ref']}\"\n",
    "    files = !gsutil ls {reference} ; assert len(files) > 1\n",
    "\n",
    "    # Get the sample\n",
    "    [index] = set(sample.keys())-{\"ref\"}\n",
    "\n",
    "    # Update the configuration\n",
    "    body = fapi.get_workspace_config(namespace, workspace, cnamespace, \"cellranger-count\").json()  \n",
    "    body[\"inputs\"][\"cellranger_count.id\"] = f'\"{id}\"'\n",
    "    body[\"inputs\"][\"cellranger_count.fastq_paths\"] = f\"{fastqs}\".replace(\"'\", '\"')\n",
    "    body[\"inputs\"][\"cellranger_count.sample\"] = f'\"{index}\"'\n",
    "    body[\"inputs\"][\"cellranger_count.reference\"] = f'\"{reference}\"'\n",
    "    body[\"inputs\"][\"cellranger_count.technique\"] = f'\"{technique}\"'\n",
    "    body[\"inputs\"][\"cellranger_count.mem_GiB\"] = f'\"{mem_GiB}\"'\n",
    "    body[\"inputs\"][\"cellranger_count.disk_GiB\"] = f'\"{disk_GiB}\"'\n",
    "    body[\"inputs\"][\"cellranger_count.count_output_path\"] = ''\n",
    "    body[\"inputs\"][\"cellranger_count.log_output_path\"] = ''\n",
    "    body[\"inputs\"][\"cellranger_count.bucket\"] = ''\n",
    "    body[\"inputs\"][\"cellranger_count.docker\"] = ''\n",
    "    body[\"inputs\"][\"cellranger_count.params\"] = f'\"{params}\"'\n",
    "    fapi.update_workspace_config(namespace, workspace, cnamespace, \"cellranger-count\", body).json()\n",
    "    submit(\"cellranger-count\", f\"{index} {bcl}\")\n",
    "    return True\n",
    "\n",
    "def run_spatial_count(bcl, sample, mm=2):\n",
    "    # Get the paths and sizes of the fastqs\n",
    "    fastqs, total_size_GiB, id = get_fastqs_and_size_and_id(bcl, sample)\n",
    "    mem_GiB = max(math.ceil(total_size_GiB * mm), 64)\n",
    "    disk_GiB = max(math.ceil(total_size_GiB * mm), 64)\n",
    "    assert disk_GiB <= 640, \"Increase memory cap\"\n",
    "    assert disk_GiB <= 6000, \"Increase disk cap\"\n",
    "    \n",
    "    # Get the pucks\n",
    "    pucks = sample[\"puck\"]\n",
    "    for puck in pucks:\n",
    "        res = !gsutil stat {puck}\n",
    "        assert len(res) > 1\n",
    "\n",
    "    # Update the configuration\n",
    "    body = fapi.get_workspace_config(namespace, workspace, cnamespace, \"spatial-count\").json()  \n",
    "    body[\"inputs\"][\"spatial_count.id\"] = f'\"{id}\"'\n",
    "    body[\"inputs\"][\"spatial_count.fastq_paths\"] = f\"{fastqs}\".replace(\"'\", '\"')\n",
    "    body[\"inputs\"][\"spatial_count.pucks\"] = f\"{pucks}\".replace(\"'\", '\"')\n",
    "    body[\"inputs\"][\"spatial_count.mem_GiB\"] = f'\"{mem_GiB}\"'\n",
    "    body[\"inputs\"][\"spatial_count.disk_GiB\"] = f'\"{disk_GiB}\"'\n",
    "    body[\"inputs\"][\"spatial_count.count_output_path\"] = ''\n",
    "    body[\"inputs\"][\"spatial_count.log_output_path\"] = ''\n",
    "    body[\"inputs\"][\"spatial_count.bucket\"] = ''\n",
    "    body[\"inputs\"][\"spatial_count.docker\"] = ''\n",
    "    fapi.update_workspace_config(namespace, workspace, cnamespace, \"spatial-count\", body).json()\n",
    "    submit(\"spatial-count\", f\"{id}\")\n",
    "    return True\n",
    "\n",
    "def run_positioning(bcl, sample, mm=2):\n",
    "    pass\n",
    "\n",
    "def run_reconstruction(bcl, sample, params=\"\", mm=1.5):\n",
    "    # Get the paths and sizes of the fastqs\n",
    "    fastqs, total_size_GiB, id = get_fastqs_and_size_and_id(bcl, sample)\n",
    "    mem_GiB = max(math.ceil(total_size_GiB * mm), 64)\n",
    "    disk_GiB = max(math.ceil(total_size_GiB * mm), 64)\n",
    "    assert mem_GiB  <= 640, \"Increase memory cap\"\n",
    "    assert disk_GiB <= 6000, \"Increase disk cap\"\n",
    "    \n",
    "    # Update the configuration\n",
    "    body = fapi.get_workspace_config(namespace, workspace, cnamespace, \"reconstruction\").json()  \n",
    "    body[\"inputs\"][\"reconstruction.id\"] = f'\"{id}\"'\n",
    "    body[\"inputs\"][\"reconstruction.fastq_paths\"] = f\"{fastqs}\".replace(\"'\", '\"')\n",
    "    body[\"inputs\"][\"reconstruction.params\"] = f'\"{params}\"'\n",
    "    body[\"inputs\"][\"reconstruction.mem_GiB\"] = f'\"{mem_GiB}\"'\n",
    "    body[\"inputs\"][\"reconstruction.disk_GiB\"] = f'\"{disk_GiB}\"'\n",
    "    body[\"inputs\"][\"reconstruction.recon_output_path\"] = ''\n",
    "    body[\"inputs\"][\"reconstruction.log_output_path\"] = ''\n",
    "    body[\"inputs\"][\"reconstruction.bucket\"] = ''\n",
    "    body[\"inputs\"][\"reconstruction.docker\"] = ''\n",
    "    fapi.update_workspace_config(namespace, workspace, cnamespace, \"reconstruction\", body).json()\n",
    "    submit(\"reconstruction\", f\"{id} {params}\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 fastqs found\n",
      "total size: 103 GiB\n",
      "id: 240911_SL-EXD_0362_A22FLV2LT4/SI-TT-D1\n",
      "Submitted spatial-count 240911_SL-EXD_0362_A22FLV2LT4/SI-TT-D1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[run_spatial_count(bcl, sample, mm=2) for sample in run_data[\"spatial-count\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 fastqs found\n",
      "total size: 103 GiB\n",
      "id: 240911_SL-EXD_0362_A22FLV2LT4/SI-TT-D1\n",
      "Submitted spatial-count 240911_SL-EXD_0362_A22FLV2LT4/SI-TT-D1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_spatial_count(bcl, run_data[\"spatial-count\"][0], mm=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "# List all submissions\n",
    "subs = fapi.list_submissions(\"testmybroad\", \"Macosko-Pipelines\").json()\n",
    "subs = [sub for sub in subs if sub[\"status\"] not in [\"Done\",\"Aborted\"]]\n",
    "print(len(subs))\n",
    "\n",
    "# Abort all submissions\n",
    "# ids = [sub[\"submissionId\"] for sub in subs]\n",
    "# [fapi.abort_submission(\"testmybroad\", \"Macosko-Pipelines\", submission_id) for submission_id in ids]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
